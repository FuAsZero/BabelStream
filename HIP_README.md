Here is guidance on how to write stream load/store performant HIP code.
=================

1. Wider load/store can improve performance. Our ISA have global_load_dwordx4/global_store_dwordx4, which introduce less commands than global_load_dword/global_store_dword.

2. You can check the ISA code generated by compiler, ISA code can help you understand performance difference:
  ```
  export KMDUMPLLVM=1
  export KMDUMPISA=1
  ```
  compile your codes, you can find "dump-gfx906.isa" (if your are using MI50).

3. More threads in a WordGroup doesn't always introduce better performance. 
There are limited vGPR/sGPR/LDS resource in single SIMD/CU, more threads will reduce the vGPR/sGPR/LDS can be used by each thread. 
Original TBSIZE (threadBlock size) is 1024, here we suggest to use 128.

4. We have 60CU in MI50, each CU has 4 SIMD, totally 240 SIMD. 
Each WorkGroup will be dispatched on one SIMD, so when you change DOT_NUM_BLOCKS (number of WorkGroups for DOT kernel) from 256 to 240, you can see performance improvement.
And please remember to change ARRAY_SIZE compliant with DOT_NUM_BLOCKS.

5. Take add_kernel as an example, to generate dwordx4 load/store ISA, you can change your code as:
```cpp
template <>
__global__ void add_kernel<float>(const float * a, const float * b, float * c)
{
  const int i = (hipBlockDim_x * hipBlockIdx_x + hipThreadIdx_x)*4;

  float4 * src_a = (float4 *) (a+i);
  float4 * src_b = (float4 *) (b+i);
  float4 * dst   = (float4 *) (c+i);

  *dst = *src_a + *src_b;
}
```
6. If you are dealing with double datatype, you need 2 double to assemble a dwordx4 load/store, like:
```cpp
template <>
__global__ void add_kernel<double>(const double * a, const double * b, double * c)
{
  const int i = (hipBlockDim_x * hipBlockIdx_x + hipThreadIdx_x)*2;

  double2 * src_a = (double2 *) (a+i);
  double2 * src_b = (double2 *) (b+i);
  double2 * dst   = (double2 *) (c+i);

  *dst = *src_a + *src_b;
}
```
We have dwordx2 support, so you can find double type performs better than float type in original single data operator.

7. Summary:
* let compiler generate as less address calculation ISA as possible;
* let compiler easily know it can assemble consecutive load/store into dwordx4 operator, ex. using datatype float4/double2;
* HW support at most 1024 threads per WorkGroup, but more threads indicate less HW resource;
